"""
Clustering Model
KMeans clustering to identify spending personas
"""

import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from typing import Dict, List, Tuple
import joblib
import os


class SpendingClusterModel:
    """KMeans clustering model for spending pattern analysis"""
    
    # Spending persona definitions
    PERSONAS = {
        0: {
            "name": "ê· í˜•ìž¡ížŒ ì†Œë¹„ìž",
            "icon": "âš–ï¸",
            "description": "ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì— ê³ ë¥´ê²Œ ì§€ì¶œí•˜ë©°, ê³„íšì ì¸ ì†Œë¹„ íŒ¨í„´ì„ ë³´ìž…ë‹ˆë‹¤.",
            "strengths": ["ê· í˜•ìž¡ížŒ ì§€ì¶œ", "ê³„íšì  ì†Œë¹„"],
            "tips": ["í˜„ìž¬ì˜ ê· í˜•ì„ ìœ ì§€í•˜ì„¸ìš”", "ì €ì¶• ëª©í‘œë¥¼ ì„¤ì •í•´ë³´ì„¸ìš”"]
        },
        1: {
            "name": "ì‹ìƒí™œ ì¤‘ì‹¬í˜•",
            "icon": "ðŸ½ï¸",
            "description": "ì‹ë¹„ ì§€ì¶œì´ ë†’ì€ íŽ¸ìž…ë‹ˆë‹¤. ì™¸ì‹ì´ë‚˜ ë°°ë‹¬ì„ ìžì£¼ ì´ìš©í•˜ëŠ” ê²½í–¥ì´ ìžˆìŠµë‹ˆë‹¤.",
            "strengths": ["ìŒì‹ ë¬¸í™” í–¥ìœ "],
            "tips": ["ì£¼ 2íšŒ ì§ì ‘ ìš”ë¦¬í•´ë³´ê¸°", "ë°°ë‹¬ ìŒì‹ ì¤„ì´ê¸°", "ì‹ë¹„ ì˜ˆì‚° ì„¤ì •"]
        },
        2: {
            "name": "ì ˆì•½í˜• ì†Œë¹„ìž",
            "icon": "ðŸ’°",
            "description": "ì „ë°˜ì ìœ¼ë¡œ ì†Œë¹„ê°€ ì ê³  ì €ì¶• ì„±í–¥ì´ ê°•í•©ë‹ˆë‹¤.",
            "strengths": ["ë†’ì€ ì €ì¶•ë¥ ", "ê³„íšì  ì†Œë¹„"],
            "tips": ["ê°€ë”ì€ ìžì‹ ì„ ìœ„í•œ ì†Œë¹„ë„ ì¢‹ì•„ìš”", "ìž¥ê¸° íˆ¬ìž ê³ ë ¤í•˜ê¸°"]
        },
        3: {
            "name": "ë¬¸í™”ìƒí™œ ì• í˜¸ê°€",
            "icon": "ðŸŽ¬",
            "description": "ì—¬ê°€ì™€ ë¬¸í™” í™œë™ì— ì ê·¹ì ìœ¼ë¡œ íˆ¬ìží•©ë‹ˆë‹¤.",
            "strengths": ["ì‚¶ì˜ ì§ˆ ì¶”êµ¬", "ê²½í—˜ ì¤‘ì‹œ"],
            "tips": ["ë¬´ë£Œ ë¬¸í™” í–‰ì‚¬ í™œìš©í•˜ê¸°", "êµ¬ë… ì„œë¹„ìŠ¤ ì •ë¦¬í•˜ê¸°"]
        },
        4: {
            "name": "ê¸°ìˆ  íˆ¬ìží˜•",
            "icon": "ðŸ’»",
            "description": "ê¸°ìˆ  ë° êµìœ¡ì— íˆ¬ìžë¥¼ ì•„ë¼ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            "strengths": ["ìžê¸°ê³„ë°œ", "ë¯¸ëž˜ íˆ¬ìž"],
            "tips": ["ë¬´ë£Œ ì˜¨ë¼ì¸ ê°•ì˜ í™œìš©", "ì¤‘ê³  ê¸°ê¸° ê³ ë ¤í•˜ê¸°"]
        }
    }
    
    def __init__(self, n_clusters: int = 5):
        """
        Initialize clustering model
        
        Args:
            n_clusters: Number of clusters (spending personas)
        """
        self.n_clusters = n_clusters
        self.model = KMeans(
            n_clusters=n_clusters,
            random_state=42,
            n_init=10
        )
        self.is_fitted = False
        self.cluster_centers = None
        
    def fit(self, X: np.ndarray) -> 'SpendingClusterModel':
        """
        Fit the clustering model
        
        Args:
            X: Feature matrix (samples Ã— features)
        
        Returns:
            Self for chaining
        """
        self.model.fit(X)
        self.cluster_centers = self.model.cluster_centers_
        self.is_fitted = True
        
        print(f"âœ… KMeans model fitted with {self.n_clusters} clusters")
        return self
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Predict cluster labels
        
        Args:
            X: Feature matrix
        
        Returns:
            Array of cluster labels
        """
        if not self.is_fitted:
            raise ValueError("Model must be fitted before prediction")
        
        return self.model.predict(X)
    
    def get_persona(self, cluster_id: int) -> Dict:
        """
        Get persona information for a cluster
        
        Args:
            cluster_id: Cluster ID (0 to n_clusters-1)
        
        Returns:
            Dict with persona info
        """
        # Use modulo to handle cases where cluster_id >= len(PERSONAS)
        persona_id = cluster_id % len(self.PERSONAS)
        return self.PERSONAS[persona_id]
    
    def analyze_user_persona(
        self, 
        user_features: np.ndarray,
        feature_names: List[str] = None
    ) -> Dict:
        """
        Analyze user's spending persona
        
        Args:
            user_features: User's feature vector
            feature_names: Names of features
        
        Returns:
            Dict with persona analysis
        """
        if not self.is_fitted:
            raise ValueError("Model must be fitted before analysis")
        
        # Predict cluster
        cluster_id = self.predict(user_features.reshape(1, -1))[0]
        
        # Get persona info
        persona = self.get_persona(cluster_id)
        
        # Calculate distance to cluster center (how typical the user is)
        distance = np.linalg.norm(
            user_features - self.cluster_centers[cluster_id]
        )
        
        # Normalize distance to 0-100 scale (lower is more typical)
        max_distance = np.max([
            np.linalg.norm(center) 
            for center in self.cluster_centers
        ])
        typicality_score = max(0, 100 - (distance / max_distance) * 100)
        
        return {
            "cluster_id": int(cluster_id),
            "persona_name": persona["name"],
            "persona_icon": persona["icon"],
            "description": persona["description"],
            "strengths": persona["strengths"],
            "tips": persona["tips"],
            "typicality_score": float(typicality_score),
            "is_typical": typicality_score > 60
        }
    
    def get_cluster_statistics(self, X: np.ndarray) -> Dict:
        """
        Get statistics about all clusters
        
        Args:
            X: Feature matrix
        
        Returns:
            Dict with cluster statistics
        """
        if not self.is_fitted:
            raise ValueError("Model must be fitted before analysis")
        
        labels = self.predict(X)
        
        stats = {}
        for i in range(self.n_clusters):
            cluster_mask = labels == i
            cluster_size = np.sum(cluster_mask)
            cluster_pct = (cluster_size / len(labels)) * 100
            
            stats[i] = {
                "size": int(cluster_size),
                "percentage": float(cluster_pct),
                "persona": self.get_persona(i)["name"]
            }
        
        return stats
    
    def save(self, path: str = "saved_models/clustering_model.joblib"):
        """
        Save model to disk
        
        Args:
            path: Path to save file
        """
        os.makedirs(os.path.dirname(path), exist_ok=True)
        joblib.dump({
            'model': self.model,
            'n_clusters': self.n_clusters,
            'is_fitted': self.is_fitted,
            'cluster_centers': self.cluster_centers
        }, path)
        print(f"âœ… Clustering model saved to {path}")
    
    @classmethod
    def load(cls, path: str = "saved_models/clustering_model.joblib") -> 'SpendingClusterModel':
        """
        Load model from disk
        
        Args:
            path: Path to saved file
        
        Returns:
            Loaded model instance
        """
        if not os.path.exists(path):
            raise FileNotFoundError(f"Model not found at {path}")
        
        data = joblib.load(path)
        model_instance = cls(n_clusters=data['n_clusters'])
        model_instance.model = data['model']
        model_instance.is_fitted = data['is_fitted']
        model_instance.cluster_centers = data['cluster_centers']
        
        print(f"âœ… Clustering model loaded from {path}")
        return model_instance


# Singleton instance
_cluster_model = None

def get_cluster_model() -> SpendingClusterModel:
    """Get or create clustering model singleton instance"""
    global _cluster_model
    if _cluster_model is None:
        _cluster_model = SpendingClusterModel()
    return _cluster_model
